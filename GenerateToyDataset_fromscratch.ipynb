{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a Toy Dataset from the LIDC-IDRI CT scans\n",
    "\n",
    "To be able to test wether our MaskRCNN works properly, we need a ToyDataset, that is surely an easy enough job for the NN. \n",
    "We need a dataset with which we can test:\n",
    "- classification\n",
    "- segmentation\n",
    "- bounding box generation\n",
    "\n",
    "For this we generate a dataset of 2D CT slices containing heart or star shaped masks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import nrrd\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "import pylidc as pl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.set_cmap('gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctpath='LIDC-30/images/images'#define the path to the CT slices\n",
    "normalizedctpath='LIDC-30/normalized_cts'#define the path to the normalized CTs\n",
    "toydatasetpath='LIDC-30/toydataset'#define the path to the toydataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we choose some CT slices. For this you need to download the LIDC dataset, and have a configfile, as follows:\n",
    "- On Windows, the file should be located at C:Users[User]pylidc.conf\n",
    "- On Linux and Mac, the file should be located at /home/[user]/.pylidcrc\n",
    "\n",
    "The config file has to contain the path to the LIDC-IDRI dataset, looking like this:\n",
    "\n",
    "[dicom]\\\n",
    "path = /path/to/big_external_drive/datasets/LIDC-IDRI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/cusniwtt/Documents/GitHub/maskrcnn-from-scratch/LIDC-30/images/images'\n",
    "f = open('/Users/cusniwtt/.pylidcrc', 'w')\n",
    "f.write(f'[dicom]\\npath = {path}\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download CT slices from the LIDC-IDRI dataset. This function downloads slices based on the annotation/nodule malignancy score\n",
    "def getMalignancyByScore(score):\n",
    "    anns = pl.query(pl.Annotation).filter(pl.Annotation.malignancy == score)\n",
    "    n=0\n",
    "    for a in anns:\n",
    "        scan=pl.query(pl.Scan).filter(pl.Scan.id == a.scan_id).first()\n",
    "        scan=scan.to_volume()\n",
    "        for i in a.contour_slice_indices:\n",
    "            scanslice=scan[:,:,i]\n",
    "            n+=1\n",
    "            if n==5000:\n",
    "                return\n",
    "            filepath=os.path.join(ctpath,str(n))\n",
    "            np.save(filepath,scanslice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getMalignancyByScore(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom as dicom\n",
    "ctpath = 'LIDC-30/images/images' #bypass it for now\n",
    "ctpath = os.listdir(path)\n",
    "ctpath = [os.path.join(path, i) for i in ctpath]\n",
    "ctpath.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CT slice values can be very high/low with outstanding values. Lets normalize them to the range 0-255\n",
    "numoffiles=len(ctpath)\n",
    "allcts=np.zeros((numoffiles,512,512))\n",
    "for num,file in enumerate(ctpath):\n",
    "    ds = dicom.dcmread(file)\n",
    "    pixel_array_numpy = ds.pixel_array\n",
    "\n",
    "    #im=np.load(os.path.join(ctpath,file))\n",
    "    im=pixel_array_numpy\n",
    "    avg=np.mean(im)\n",
    "    std=np.std(im)\n",
    "    im=(im-avg)/std\n",
    "    immin=np.amin(im)\n",
    "    im=im-immin\n",
    "    immax=np.amax(im)\n",
    "    im=im/immax\n",
    "    im=im*255\n",
    "    res = cv2.resize(im, dsize=(512, 512), interpolation=cv2.INTER_CUBIC) # for fix to 512x512\n",
    "    allcts[num]=res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets save the normalized CTs\n",
    "for num, im in enumerate(allcts):\n",
    "    filename=str(num).zfill(6)+'.npy'\n",
    "    file=os.path.join(normalizedctpath,filename)\n",
    "    np.save(file,im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 65, 65)\n",
      "0.0 1.0 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "#Lets load our masks\n",
    "masks=np.zeros([2,65,65],dtype=np.float32)\n",
    "maskfolder='./masks'\n",
    "for num,file in enumerate(os.listdir(maskfolder)):\n",
    "    img=Image.open(os.path.join(maskfolder,file))\n",
    "    data = np.array(img, dtype='float32' )\n",
    "    masks[num]=data[:,:,0]\n",
    "\n",
    "print(masks.shape)\n",
    "maskx=masks[0].shape[0]\n",
    "masky=masks[0].shape[1]\n",
    "\n",
    "masks=(masks/255)\n",
    "print(np.amin(masks),np.amax(masks),np.amin(masks),np.amax(masks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate a JSON file\n",
    "\n",
    "First we generate a json file, which randomly choses mask to the CTslice. The possibilities are: \n",
    "- nothing\n",
    "- star\n",
    "- heart\n",
    "- heart and star\n",
    ",it also generates a placement to them (xmin, ymin), and a random resize factor (factor 0.6-1).\n",
    "It will contain the bbox coordinates as well (xmin,ymin,xmax,ymax).\n",
    "\n",
    "We will generate our toydataset from this json.\n",
    "\n",
    "The file will look as:\n",
    "dictionary{filename: dictionary2} in the dictionary the keys are the filenames, the values are dictionaries, containing the informations about the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_in=ctpath\n",
    "numoffiles=len(os.listdir(ctpath))\n",
    "datasetInfo={}\n",
    "\n",
    "for num in range(numoffiles):  \n",
    "    rx=random.randint(150,350)\n",
    "    ry=random.randint(150,350)\n",
    "    rm=random.randint(0,3)\n",
    "    rf=random.randint(6,10)/10\n",
    "    ns=round(rf*maskx)\n",
    "\n",
    "    if rm == 0:\n",
    "        rm=[1,0]\n",
    "        x1=rx\n",
    "        x2=rx+ns\n",
    "        y1=ry\n",
    "        y2=ry+ns\n",
    "        bbox=[[x1,y1,x2,y2]]\n",
    "        \n",
    "        datasetInfo[str(num).zfill(6)+'.nrrd']={'label': rm,'xmin':rx,'ymin': ry,'factor': rf , 'size': ns,'bbox':bbox}\n",
    "    elif rm == 1:\n",
    "        rm=[0,1]\n",
    "        \n",
    "        x1=rx\n",
    "        x2=rx+ns\n",
    "        y1=ry\n",
    "        y2=ry+ns\n",
    "        bbox=[[x1,y1,x2,y2]]\n",
    "        \n",
    "        \n",
    "        datasetInfo[str(num).zfill(6)+'.nrrd']={'label': rm,'xmin':rx,'ymin': ry,'factor': rf , 'size': ns,'bbox':bbox}\n",
    "    elif rm==3:\n",
    "        rm=[1,1]\n",
    "        rx2=random.randint(150,300)\n",
    "        ry2=random.randint(150,300)\n",
    "        rf2=random.randint(3,10)/10\n",
    "        ns2=round(rf2*maskx)\n",
    "        \n",
    "        x11=rx\n",
    "        x21=rx+ns\n",
    "        y11=ry\n",
    "        y21=ry+ns\n",
    "        \n",
    "        bbox1=[x11,y11,x21,y21]\n",
    "        \n",
    "        x12=rx2\n",
    "        x22=rx2+ns2\n",
    "        y12=ry2\n",
    "        y22=ry2+ns2\n",
    "        \n",
    "        bbox2=[x12,y12,x22,y22]\n",
    "        bbox=[bbox1,bbox2]\n",
    "        \n",
    "        rx=[rx,rx2]\n",
    "        ry=[ry,ry2]\n",
    "        rf=[rf,rf2]\n",
    "        ns=[ns,ns2]\n",
    "    \n",
    "        datasetInfo[str(num).zfill(6)+'.nrrd']={'label': rm,'xmin':rx, 'ymin': ry, 'factor': rf, 'size': ns,'bbox':bbox }\n",
    "    else:\n",
    "        rm=[0,0]\n",
    "        datasetInfo[str(num).zfill(6)+'.nrrd']={'label': rm,'xmin':0,'ymin': 0,'factor': 0 ,'size': 0,'bbox':[[0,0,0,0]]}\n",
    "        \n",
    "\n",
    "with open(os.path.join(toydatasetpath,'dataInfo.json'), 'w') as f:\n",
    "    json_object = json.dump(datasetInfo,f)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate toydataset from the json file. We will also modify the json file, as we calculate the contrast for each mask, and save that to the jsonfile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pernum=5\n",
    "folder_in=normalizedctpath\n",
    "dataFolder=os.path.join(toydatasetpath,'images')\n",
    "maskFolder=os.path.join(toydatasetpath,'masks')\n",
    "\n",
    "with open(os.path.join(toydatasetpath,'dataInfo.json')) as j:\n",
    "     dataInfo_ = json.loads(j.read())\n",
    "        \n",
    "totalMask=np.zeros((512,512))\n",
    "for file in dataInfo_.keys():\n",
    "    #read in the proper npy file\n",
    "    npfile=re.findall('\\d+', file )[0]+'.npy'\n",
    "    im=np.squeeze(np.load(os.path.join(folder_in,npfile)))\n",
    "    im=(np.array(im,dtype=np.float32))\n",
    "    maskfile=np.copy(totalMask)\n",
    "    immax=np.amax(im)\n",
    "    \n",
    "    label=dataInfo_[file]['label']\n",
    "    \n",
    "    if label==[1,1]:\n",
    "        \n",
    "        f0=dataInfo_[file]['factor'][0]\n",
    "        f1=dataInfo_[file]['factor'][1]\n",
    "\n",
    "        x0=dataInfo_[file]['xmin'][0]\n",
    "        x1=dataInfo_[file]['xmin'][1]\n",
    "        \n",
    "        y0=dataInfo_[file]['ymin'][0]\n",
    "        y1=dataInfo_[file]['ymin'][1]\n",
    "        \n",
    "        newsize0 = (round(maskx*f0),round(masky*f0))\n",
    "        ns0=newsize0[0]\n",
    "        newsize1 = (round(maskx*f1),round(masky*f1))\n",
    "        ns1=newsize1[0]\n",
    "\n",
    "        mask0 = cv2.resize(np.copy(masks[0]),(newsize0))*immax/pernum\n",
    "        mask1 = cv2.resize(np.copy(masks[1]),(newsize1))*immax/pernum\n",
    "\n",
    "        origsquare0=np.copy(im[x0:x0+ns0,y0:y0+ns0])\n",
    "        \n",
    "        im[x0:x0+ns0,y0:y0+ns0]=im[x0:x0+ns0,y0:y0+ns0]+mask0\n",
    "        maskfile[x0:x0+ns0,y0:y0+ns0]=maskfile[x0:x0+ns0,y0:y0+ns0]+mask0*100\n",
    "        newimmax0=np.amax(im)\n",
    "        im[im>immax]=immax\n",
    "        maskfile[maskfile>0.5]=1\n",
    "        \n",
    "        maskedsquare0=np.copy(im[x0:x0+ns0,y0:y0+ns0])\n",
    "        \n",
    "        maskintensity=np.mean(maskedsquare0[maskedsquare0!=origsquare0])\n",
    "        backgroundintensity=np.mean(maskedsquare0[maskedsquare0==origsquare0])\n",
    "        c0=str((maskintensity-backgroundintensity)/backgroundintensity)\n",
    "        \n",
    "        origsquare1=np.copy(im[x1:x1+ns1,y1:y1+ns1])\n",
    "        \n",
    "        im[x1:x1+ns1,y1:y1+ns1]=im[x1:x1+ns1,y1:y1+ns1]+mask1\n",
    "        maskfile[x1:x1+ns1,y1:y1+ns1]=maskfile[x1:x1+ns1,y1:y1+ns1]+mask1*100\n",
    "        newimmax1=np.amax(im)\n",
    "\n",
    "        im[im>immax]=immax\n",
    "        maskfile[maskfile>0.5]=1\n",
    "        \n",
    "        maskedsquare1=np.copy(im[x1:x1+ns1,y1:y1+ns1])\n",
    "        maskintensity=np.mean(maskedsquare1[maskedsquare1!=origsquare1])\n",
    "        backgroundintensity=np.mean(maskedsquare1[maskedsquare1==origsquare1])\n",
    "        c1=str((maskintensity-backgroundintensity)/backgroundintensity)\n",
    "    \n",
    "        dataInfo_[file]['contrast']=[c0,c1]\n",
    "        nrrd.write(os.path.join(dataFolder,file),im)\n",
    "        nrrd.write(os.path.join(maskFolder,file),maskfile)\n",
    "        \n",
    "    elif label==[0,0]:\n",
    "        \n",
    "        dataInfo_[file]['contrast']=0\n",
    "        nrrd.write(os.path.join(dataFolder,file),im)\n",
    "        nrrd.write(os.path.join(maskFolder,file),maskfile)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        label=np.argmax(label)\n",
    "        f=dataInfo_[file]['factor']\n",
    "        x=dataInfo_[file]['xmin']\n",
    "        y=dataInfo_[file]['ymin'] \n",
    "        newsize = (round(maskx*f),round(masky*f))\n",
    "        ns=newsize[0]\n",
    "        mask = cv2.resize(np.copy(masks[label]),(newsize))*immax/pernum\n",
    "        origsquare=np.copy(im[x:x+ns,y:y+ns])\n",
    "\n",
    "        im[x:x+ns,y:y+ns]=im[x:x+ns,y:y+ns]+mask\n",
    "        maskfile[x:x+ns,y:y+ns]=maskfile[x:x+ns,y:y+ns]+mask*100\n",
    "        newimmax=np.amax(im)\n",
    "\n",
    "        im[im>immax]=immax\n",
    "        maskfile[maskfile>0.5]=1\n",
    "        \n",
    "        maskedsquare=np.copy(im[x:x+ns,y:y+ns])\n",
    "        \n",
    "        maskintensity=np.mean(maskedsquare[maskedsquare!=origsquare])\n",
    "        backgroundintensity=np.mean(maskedsquare[maskedsquare==origsquare])\n",
    "        c=str((maskintensity-backgroundintensity)/backgroundintensity)   \n",
    "        dataInfo_[file]['contrast']=c\n",
    "        nrrd.write(os.path.join(dataFolder,file),im)\n",
    "        nrrd.write(os.path.join(maskFolder,file),maskfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets overwrite the json file, to contain the contrast values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(toydatasetpath,'dataInfo.json'), 'w') as f:\n",
    "    json_object = json.dump(dataInfo_,f)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking generated images and the saved informations\n",
    "\n",
    "Lets check some saved images, to see if the generated informations are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_to_rect(bboxparam):\n",
    "    # Convert the bounding box to 4 lines in matplotlib to visualize it. boundingbox=[min_x,min_y,max_x,max_y]\n",
    "    #in matplotlib line=start_x,end_x,start_y,end_y\n",
    "    #so line by line: lowerline=[x1,x2],[y1,y1] #upperline=[x1,x2],[y2,y2] #leftsideline=[x1,x1],[y1,y2] #rightsideline=[x2,x2],[y1,y2]\n",
    "        y1=bboxparam[0]\n",
    "        y2=bboxparam[2]\n",
    "        x1=bboxparam[1]\n",
    "        x2=bboxparam[3]\n",
    "        boxlines=[x1,x2],[y1,y1],[x1,x2],[y2,y2],[x1,x1],[y1,y2],[x2,x2],[y1,y2]\n",
    "        #to visualize use: matplotlib.plot(*bbox_to_rect(boundingbox),color='green')  on the same plot where imshow shows the mask\n",
    "        return boxlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.36796343', '0.32080352']\n",
      "['0.36796343', '0.32080352']\n",
      "['0.21425511', '0.41122118']\n",
      "['0.21425511', '0.41122118']\n",
      "['0.47720486', '0.38375378']\n",
      "['0.47720486', '0.38375378']\n",
      "0.48522413\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(toydatasetpath,'dataInfo.json')) as j:\n",
    "     toydatasetInfo = json.loads(j.read())\n",
    "        \n",
    "\n",
    "f, axarr = plt.subplots(5,2)\n",
    "n=0\n",
    "for i in range(0,5):\n",
    "    filename=str(i).zfill(6)+'.nrrd'\n",
    "    \n",
    "    data, header = nrrd.read(os.path.join(dataFolder,filename))\n",
    "    axarr[n,0].imshow(data)\n",
    "\n",
    "    mask, maskheader = nrrd.read(os.path.join(maskFolder,filename))\n",
    "    axarr[n,1].imshow(mask)\n",
    "\n",
    "    for bbox in toydatasetInfo[filename]['bbox']: \n",
    "        axarr[n,1].plot(*bbox_to_rect(bbox),color='red')\n",
    "        print(toydatasetInfo[filename]['contrast'])\n",
    "    n+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "55602505796b395471532f5081df3c4fcef54cf33e498b3a10cf72378715fc4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
