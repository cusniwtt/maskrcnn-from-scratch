{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, add, multiply\n",
    "from keras.layers import Dropout, Lambda\n",
    "from keras.layers import Conv2D, Conv2DTranspose, BatchNormalization\n",
    "from keras.layers import MaxPooling2D, UpSampling2D\n",
    "from keras.layers import concatenate, Activation\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIX PARAMETERS\n",
    "\n",
    "These could be in a config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGEFOLDER='LIDC-30/toydataset/images'\n",
    "MASKFOLDER='LIDC-30/toydataset/masks'\n",
    "NUMOFTRAINDATAS=400\n",
    "NUMOFTESTDATAS=62\n",
    "BATCHLEN=5\n",
    "BATCHPEREPOCH=NUMOFTRAINDATAS/BATCHLEN\n",
    "PROPOSALCOUNT=20\n",
    "ROISIZE=[5,5]\n",
    "MASKROISIZE=[14,14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataGenerators\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchgenerator_cnn(datafolder,jsonfile,batchlen,numofdatas=None,fromimage=0):\n",
    "    if numofdatas is None:\n",
    "        numofdatas=len(os.listdir(datafolder))\n",
    "    while True:\n",
    "        indices = np.arange(fromimage,numofdatas)\n",
    "        np.random.shuffle(indices)\n",
    "        for batchstart in range(0+fromimage,fromimage+numofdatas,batchlen):\n",
    "            x_batch=np.zeros((batchlen,512,512),dtype=np.float32)      \n",
    "            y_batch=np.zeros((batchlen,2),dtype=np.float32)      \n",
    "            filenames=[]\n",
    "            for num,i in enumerate(indices[batchstart:batchstart+batchlen]):\n",
    "                filename=str(i).zfill(6)+'.nrrd'\n",
    "                data, h_=nrrd.read(os.path.join(datafolder,filename))\n",
    "                x_batch[num]=data\n",
    "                y_batch[num]=jsonfile[filename]['label']\n",
    "                filenames.append(filename)\n",
    "            if len(filenames)!=batchlen:\n",
    "                continue\n",
    "            else:\n",
    "                x_batch=np.expand_dims(x_batch,-1)\n",
    "                yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchgenerator_maskrcnn(datafolder,maskfolder,jsonfile,batchlen,numofdatas=None,mode='Complextrain',fromimage=0):\n",
    "    if numofdatas is None:\n",
    "        numofdatas=len(os.listdir(datafolder))\n",
    "    indices = np.arange(fromimage,numofdatas)\n",
    "    np.random.shuffle(indices)\n",
    "    for batchstart in range(0+fromimage,fromimage+numofdatas,batchlen):\n",
    "        x_batch=np.zeros((batchlen,512,512),dtype=np.float32)  \n",
    "        y_batch=np.zeros((batchlen,2),dtype=np.float32)        \n",
    "        m_batch=np.zeros((batchlen,512,512),dtype=np.float32)      \n",
    "        bb_batch=[]\n",
    "        filenames=[]\n",
    "        for num,i in enumerate(indices[batchstart:batchstart+batchlen]):\n",
    "            filename=str(i).zfill(6)+'.nrrd'\n",
    "            data, h_=nrrd.read(os.path.join(datafolder,filename))\n",
    "            x_batch[num]=data\n",
    "            y_batch[num]=jsonfile[filename]['label']\n",
    "            bbox=jsonfile[filename]['bbox']\n",
    "            bb_batch.append(np.asarray(bbox))\n",
    "            filenames.append(filename)\n",
    "            if mode == 'Masktrain' or mode== 'Complextrain':\n",
    "                mask, h_=nrrd.read(os.path.join(maskfolder,filename))\n",
    "                m_batch[num]=mask           \n",
    "        if (np.sum(np.sum(np.sum(bb_batch)))==0): # we can't have a batch full of only BG images, cause the boxloss only takes FGs --> it would go to Nan in case of a full BG batch\n",
    "            continue\n",
    "        elif len(filenames)!=batchlen:\n",
    "            continue\n",
    "        else:\n",
    "            x_batch=np.expand_dims(x_batch,-1)\n",
    "            if mode=='RPNtrain':\n",
    "                yield x_batch, bb_batch\n",
    "            elif mode=='Headtrain':\n",
    "                yield x_batch,y_batch,bb_batch\n",
    "            elif mode=='Masktrain':\n",
    "                m_batch=np.expand_dims(m_batch,-1)\n",
    "                yield x_batch,y_batch,bb_batch, m_batch, filenames\n",
    "            else:\n",
    "                m_batch=np.expand_dims(m_batch,-1)\n",
    "                yield x_batch,y_batch,bb_batch, m_batch, filenames\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_=tf.keras.layers.Input((512,512,1))\n",
    "\n",
    "x=tf.keras.layers.Conv2D(64, (3, 3), activation='relu',padding='same')(input_)\n",
    "x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "#256\n",
    "\n",
    "x=tf.keras.layers.Conv2D(128, (3, 3), activation='relu',padding='same')(x)\n",
    "#x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "#128\n",
    "\n",
    "\n",
    "x=tf.keras.layers.Conv2D(256, (3, 3), activation='relu',padding='same')(x)\n",
    "#x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "#64\n",
    "\n",
    "x=tf.keras.layers.Conv2D(256, (5, 5), activation='relu',padding='same')(x)\n",
    "#x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "#32\n",
    "\n",
    "featuremap=tf.keras.layers.Conv2D(256, (3, 3), activation='relu',padding='same',name='featuremap')(x)\n",
    "#x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.MaxPooling2D((2, 2))(featuremap)\n",
    "#16\n",
    "\n",
    "\n",
    "x=tf.keras.layers.Flatten()(x)\n",
    "output=tf.keras.layers.Dense(2,activation='sigmoid')(x) # a multiclass one-hot encoding needs sigmoid as the last activation\n",
    "CNNFM=tf.keras.Model(input_,featuremap,name=\"CNN_fm\")\n",
    "CNN=tf.keras.Model(input_,output,name=\"CNN\")\n",
    "\n",
    "# Default optimizer\n",
    "#CNNFM.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.BinaryCrossentropy())\n",
    "#CNN.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.BinaryCrossentropy(), metrics=tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None, threshold=0.5))\n",
    "# Change because tensorflow-macos, tensorflow-metal [add .legacy]\n",
    "CNNFM.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.BinaryCrossentropy())\n",
    "CNN.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.BinaryCrossentropy(), metrics=tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', dtype=None, threshold=0.5))\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchgen_cnn=batchgenerator_cnn(datafolder=IMAGEFOLDER,jsonfile=DATAJSON,batchlen=BATCHLEN,numofdatas=NUMOFTRAINDATAS)\n",
    "CNN.fit(batchgen_cnn,epochs=10,steps_per_epoch=BATCHPEREPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.save('./saved_models/fullbackbone_10epochs.h5')\n",
    "CNNFM.save('./saved_models/featuremapmodel_10epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnmodel=tf.keras.models.load_model('saved_models/fullbackbone_10epochs.h5')\n",
    "fmmodel=tf.keras.models.load_model('saved_models/featuremapmodel_10epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuremap=[layer for layer in cnnmodel.layers if layer.name=='featuremap']\n",
    "featuremap=featuremap[0].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURESHAPE=featuremap.shape\n",
    "FEATURESIZE=[featuremap.shape[1],featuremap.shape[2]]\n",
    "FEATUREFILTER=featuremap.shape[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating anchors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLANCHORS=utils.generate_anchors(featuremap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPN\n",
    "#### Region Proposal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RPN modell\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotNormal(seed=None)\n",
    "input_= tf.keras.layers.Input(shape=[None, None, featuremap.shape[-1]], name=\"rpn_INPUT\")\n",
    "\n",
    "shared = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu', strides=1, name='rpn_conv_shared',kernel_initializer=initializer)(input_)\n",
    "x = tf.keras.layers.Conv2D(5*2 , (1, 1), padding='valid', activation='linear',name='rpn_class_raw',kernel_initializer=initializer)(shared) \n",
    "\n",
    "rpn_class_logits = tf.keras.layers.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 2]))(x)\n",
    "rpn_probs = tf.keras.layers.Activation(\"softmax\", name=\"rpn_class_xxx\")(rpn_class_logits) # --> BG/FG\n",
    "\n",
    "# Bounding box refinement. [batch, H, W, depth]\n",
    "x = tf.keras.layers.Conv2D(5*4, (1, 1), padding=\"valid\", activation='linear', name='rpn_bbox_pred',kernel_initializer=initializer)(shared) \n",
    "\n",
    "# Reshape to [batch, anchors, 4]\n",
    "rpn_bbox = tf.keras.layers.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 4]))(x)\n",
    "outputs = [rpn_class_logits, rpn_probs, rpn_bbox]\n",
    "RPN = tf.keras.models.Model(input_, outputs, name=\"RPN\")\n",
    "\n",
    "#rpn_optimizer = tf.keras.optimizers.SGD(lr=1e-4, momentum=0.9,clipnorm=5.0)\n",
    "#rpn_optimizer = tf.keras.optimizers.Adam(lr=1e-4)\n",
    "RPN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_l1(y_true, y_pred):\n",
    "    # Take absolute difference\n",
    "    x = tf.abs(y_true - y_pred)\n",
    "    # Find indices of values less than 1\n",
    "    mask = tf.cast(tf.less(x, 1.0), \"float32\")\n",
    "    # Loss calculation for smooth l1\n",
    "    loss = (mask * (0.5 * x ** 2)) + (1 - mask) * (x - 0.5)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def rpn_loss(rpn_logits,rpn_deltas, gt_labels,gt_deltas , indices, batchlen):\n",
    "    \n",
    "    '''\n",
    "    rpn_logits,rpn_deltas: the predicted logits/deltas to all the anchors\n",
    "    gt_labels,gt_deltas: the correct labels and deltas to the chosen training anchors\n",
    "    indices: the indices of the chosen training anchors\n",
    "    '''\n",
    "\n",
    "    predicted_classes = tf.gather_nd(rpn_logits, indices)\n",
    "    foregroundindices=indices[gt_labels.astype('bool')]#labels: 0:BG  1:FG\n",
    "    predicted_deltas=tf.cast(tf.gather_nd(rpn_deltas, foregroundindices),tf.float32) #only the foreground anchors contribute to the box loss\n",
    "    gt_deltas=tf.cast(tf.gather_nd(gt_deltas, foregroundindices),tf.float32)\n",
    "\n",
    "    # Cross entropy loss\n",
    "\n",
    "    lf=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    classloss = lf(gt_labels,predicted_classes)\n",
    "    classloss=tf.reduce_mean(classloss)\n",
    "    \n",
    "    deltaloss=smooth_l1(gt_deltas,predicted_deltas)\n",
    "    deltaloss=tf.reduce_mean(deltaloss)\n",
    "    \n",
    "    return classloss,deltaloss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rpn_trainstep(rpnmodel,fmmodel):\n",
    "    #@tf.function(experimental_relax_shapes=True)\n",
    "    def rpn_trainstep(images, gt_box, batchlen, rpn_optimizer):\n",
    "        with tf.GradientTape() as gradientT:\n",
    "            featuremaps=fmmodel(images)\n",
    "            logits,probs,deltas = rpnmodel(featuremaps)    #Itt kapjuk meg az RPN kimeneteket\n",
    "            indices,gt_deltas,gt_labels=utils.indices_deltas_labels(gt_box,ALLANCHORS,batchlen,PROPOSALCOUNT,mode='pixelwise')\n",
    "            rpn_loss_class,rpn_loss_delta = rpn_loss(logits, deltas, gt_labels, gt_deltas, indices, batchlen)                \n",
    "            rpn_loss_w=rpn_loss_class+rpn_loss_delta\n",
    "        gradients_of_rpn = gradientT.gradient(rpn_loss_w, rpnmodel.trainable_variables)\n",
    "        rpn_optimizer.apply_gradients(zip(gradients_of_rpn, rpnmodel.trainable_variables))\n",
    "        return rpn_loss_w,rpn_loss_class,rpn_loss_delta\n",
    "    return rpn_trainstep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rpn(rpnmodell, fmmodel,datafolder,maskfolder,jsonfile,batchlen, epochs,numofdatas=None,rpn_optimizer=None):\n",
    "    if numofdatas is None:\n",
    "        numofdatas=len(os.listdir(datafolder))\n",
    "    if rpn_optimizer is None:\n",
    "        rpn_optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9,clipnorm=5.0)\n",
    "    trainstep=create_rpn_trainstep(rpnmodell,fmmodel)\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        losses=[]\n",
    "        losses_c=[]\n",
    "        losses_d=[]\n",
    "        batchgen=batchgenerator_maskrcnn(datafolder,maskfolder,jsonfile,batchlen,numofdatas=numofdatas,mode='RPNtrain')\n",
    "        for num,image_batch in enumerate(batchgen):\n",
    "            x,bb=image_batch\n",
    "            l,lc,ld=trainstep(x,bb,batchlen,rpn_optimizer)\n",
    "            losses.append(l)\n",
    "            losses_c.append(lc)\n",
    "            losses_d.append(ld)\n",
    "\n",
    "        end = time.time()\n",
    "        print(round(end-start),'sec. \\t',epoch,'.epoch:\\t loss(sum,c,bb):\\t', np.mean(losses),np.mean(losses_c),np.mean(losses_d))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rpn(rpnmodell=RPN,fmmodel=fmmodel,datafolder=IMAGEFOLDER,maskfolder=MASKFOLDER,jsonfile=DATAJSON,batchlen=5,epochs=20,numofdatas=NUMOFTRAINDATAS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPN.save('saved_models/rpn_20epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpnmodel=tf.keras.models.load_model('saved_models/rpn_20epochs.h5',compile=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSHEAD & BOX REFINEMENT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small class head\n",
    "input_=tf.keras.layers.Input((PROPOSALCOUNT,ROISIZE[0],ROISIZE[1],FEATUREFILTER))\n",
    "\n",
    "x=tf.keras.layers.Conv2D(kernel_size=(1,1),padding='valid',activation='relu',filters=FEATUREFILTER)(input_)\n",
    "x=tf.debugging.check_numerics(x, 'x has nan')\n",
    "x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.ReLU()(x)\n",
    "\n",
    "x=tf.keras.layers.Conv2D(kernel_size=(1,1),padding='valid',activation='relu',filters=FEATUREFILTER)(x)\n",
    "x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.ReLU()(x)\n",
    "\n",
    "flatten=tf.keras.layers.Flatten()(x)\n",
    "\n",
    "beforeclass=tf.keras.layers.Dense(PROPOSALCOUNT*3,name='beforeclasspred')(flatten)#3: numofclasses + 1 for background\n",
    "beforeclass=tf.debugging.check_numerics(beforeclass, 'beforeclass has nan')\n",
    "\n",
    "class_logits = tf.keras.layers.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], PROPOSALCOUNT,3]),name='classpred')(beforeclass)\n",
    "class_probs= tf.keras.layers.Activation(\"softmax\", name=\"classhead_class\")(class_logits) # --> BG/FG\n",
    "\n",
    "beforebox=tf.keras.layers.Dense(3*4*PROPOSALCOUNT,activation='linear',name='beforeboxpred')(flatten) # 3 is the num of classes + 1 for background\n",
    "bboxpred = tf.keras.layers.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0],PROPOSALCOUNT, 3, 4]),name='boxrefinement')(beforebox) # for every roi for every class we predict dx,dy,dw,dh\n",
    "outputs=[class_logits,class_probs,bboxpred]\n",
    "CLASSHEAD=tf.keras.Model(input_,outputs,name=\"classhead\")\n",
    "CLASSHEAD.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch_loss(ch_logits, ch_deltas, gt_labels, gt_deltas, indices):\n",
    "\n",
    "    predicted_classes = tf.gather_nd(ch_logits, indices)\n",
    "    foregroundindices=tf.where(gt_labels<2)#where the label is 2 it means it is a backrground box -> we filter these out   \n",
    "\n",
    "    classlabels=tf.cast(tf.gather_nd(gt_labels,foregroundindices),tf.int32) #the boxrefinement predicted deltas to each class; we need the proper classes to filter out the proper deltas\n",
    "    idxs=tf.range(classlabels.shape)\n",
    "    classlabels=tf.stack((idxs,classlabels),axis=1)# pred_deltas shape: (proposalcount,classes,4) -> we want to filter from axis1 -> easiest is to have 0 dimension ready with range\n",
    "    \n",
    "    pd=tf.gather_nd(ch_deltas,indices)# filter out proposed box deltas from all deltas\n",
    "    gd=tf.gather_nd(gt_deltas,indices)# filter out proposed box deltas from all deltas\n",
    "    \n",
    "    predicted_deltas=tf.cast(tf.gather_nd(pd, foregroundindices),tf.float32) #only positive boxes contribute to the box refinement loss\n",
    "    predicted_deltas=tf.cast(tf.gather_nd(predicted_deltas, classlabels),tf.float32)#only the proper classes box contribute to the box refinement loss\n",
    "    gtdeltas=tf.cast(tf.gather_nd(gd, foregroundindices),tf.float32)\n",
    "    \n",
    "\n",
    "    not_empty_images=tf.where(tf.math.logical_not(tf.reduce_all(tf.equal(gt_labels,2),axis=-1)))\n",
    "    not_empty_gts=tf.gather(gt_labels,not_empty_images,axis=0) #we dont want only background images in the classloss, that would inbalance the dataset\n",
    "    not_empty_preds=tf.gather(predicted_classes,not_empty_images,axis=0)\n",
    "    \n",
    "    # Cross entropy loss\n",
    "    lf=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    classloss = lf(not_empty_gts,not_empty_preds)\n",
    "    classloss=tf.reduce_sum(classloss)\n",
    "    \n",
    "    deltaloss=smooth_l1(gtdeltas,predicted_deltas)\n",
    "    deltaloss=tf.reduce_sum(deltaloss)\n",
    "\n",
    "    \n",
    "    return classloss,deltaloss\n",
    "\n",
    "\n",
    "def smooth_l1(y_true, y_pred):\n",
    "    # Take absolute difference\n",
    "    x = tf.abs(y_true - y_pred)\n",
    "    # Find indices of values less than 1\n",
    "    mask = tf.cast(tf.less(x, 1.0), \"float32\")\n",
    "    # Loss calculation for smooth l1\n",
    "    loss = (mask * (0.5 * x ** 2)) + (1 - mask) * (x - 0.5)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ch_trainstep(classheadmodel,rpnmodel,fmmodel):\n",
    "    #@tf.function(experimental_relax_shapes=True)\n",
    "    def ch_trainstep(images,labels, gt_box, batchlen, ch_optimizer):\n",
    "        with tf.GradientTape() as gradientT:\n",
    "            featuremaps=fmmodel(images)\n",
    "            rpn_logits,rpn_probs,rpn_boxes=rpnmodel(featuremaps)\n",
    "            proposals=utils.get_proposals(rpn_probs,rpn_boxes,ALLANCHORS)            \n",
    "            aligned_rois=utils.roi_align(featuremaps,proposals,ROISIZE)\n",
    "            ch_logits,ch_probs,ch_deltas= classheadmodel(aligned_rois)  \n",
    "            indices,gt_deltas,gt_labels=utils.head_indices_deltas_labels(gt_box, labels, proposals, batchlen=batchlen, train_set_size=6)\n",
    "            ch_classloss,ch_deltaloss = ch_loss(ch_logits, ch_deltas, gt_labels, gt_deltas, indices)   \n",
    "            ch_loss_w=ch_classloss+ch_deltaloss\n",
    "        gradients_of_classhead = gradientT.gradient(ch_loss_w, classheadmodel.trainable_variables)\n",
    "        ch_optimizer.apply_gradients(zip(gradients_of_classhead, classheadmodel.trainable_variables))\n",
    "        return ch_classloss,ch_deltaloss,\n",
    "    return ch_trainstep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classhead(classheadmodel,rpnmodel, fmmodel,numofdatas,datafolder,maskfolder,jsonfile,batchlen, epochs,ch_optimizer=None):\n",
    "    if ch_optimizer is None:\n",
    "        #ch_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001,clipvalue=0.5,clipnorm=1)\n",
    "        ch_optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001,momentum=0.9,clipnorm=5.0)\n",
    "    trainstep=create_ch_trainstep(classheadmodel,rpnmodel,fmmodel)\n",
    "    for epoch in range(epochs):\n",
    "        losses_c=[]\n",
    "        losses_d=[]\n",
    "        start = time.time()\n",
    "        batchgen=batchgenerator_maskrcnn(datafolder,maskfolder,jsonfile,batchlen,numofdatas,mode='Headtrain',fromimage=5)\n",
    "        for num,image_batch in enumerate(batchgen):\n",
    "            x,y,bb=image_batch\n",
    "            classloss,deltaloss=trainstep(x,y,bb,batchlen,ch_optimizer)\n",
    "            losses_c.append(classloss)\n",
    "            losses_d.append(deltaloss)\n",
    "        end = time.time()\n",
    "        print(round(end-start),'sec. \\t',epoch,'.epoch: \\t loss(c,bb):\\t',np.mean(losses_c),np.mean(losses_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classhead(classheadmodel=CLASSHEAD,rpnmodel=rpnmodel,fmmodel=fmmodel,numofdatas=NUMOFTRAINDATAS,\n",
    "                datafolder=IMAGEFOLDER,maskfolder=MASKFOLDER,jsonfile=DATAJSON,batchlen=5,epochs=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSHEAD.save('saved_models/classhead_20epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classheadmodel=tf.keras.models.load_model('saved_models/classhead_20epochs.h5',compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MASKHEAD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape: [batch, num_rois, MASK_POOL_SIZE, MASK_POOL_SIZE, channels]\n",
    "\n",
    "input_=tf.keras.layers.Input((PROPOSALCOUNT,MASKROISIZE[0],MASKROISIZE[1],FEATUREFILTER))\n",
    "\n",
    "x=tf.keras.layers.Conv2D(kernel_size=(1,1),padding='same',activation='relu',filters=FEATUREFILTER/2)(input_)\n",
    "x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.ReLU()(x)\n",
    "\n",
    "x=tf.keras.layers.Conv2D(kernel_size=(3,3),padding='same',activation='relu',filters=FEATUREFILTER/2)(x)\n",
    "x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.ReLU()(x)\n",
    "\n",
    "\n",
    "x=tf.keras.layers.Conv2D(kernel_size=(3,3),padding='same',activation='relu',filters=FEATUREFILTER/2)(x)\n",
    "x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.ReLU()(x)\n",
    "\n",
    "x=tf.keras.layers.TimeDistributed(tf.keras.layers.UpSampling2D(size=(2,2)))(x)\n",
    "x=tf.keras.layers.ReLU()(x)\n",
    "pred_mask=tf.keras.layers.Conv2D(kernel_size=(1,1),padding='same',activation='sigmoid',filters=2)(x) #2 filters, as we predict a mask for each class \n",
    "\n",
    "MASKHEAD=tf.keras.Model(input_,pred_mask,name=\"maskhead\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_loss(pred_mask,gt_mask,gt_labels,indices):\n",
    "    \n",
    "    foregroundindices=tf.where(gt_labels<2)\n",
    "    classlabels=tf.cast(tf.gather_nd(gt_labels,foregroundindices),tf.int32)\n",
    "    idxs=tf.range(classlabels.shape)\n",
    "    classlabels=tf.stack((idxs,classlabels),axis=1)\n",
    "    \n",
    "    pm=tf.cast(tf.gather_nd(pred_mask,indices),tf.float32)\n",
    "    pm=tf.gather_nd(pm,foregroundindices)\n",
    "    pm=tf.transpose(pm,[0,3,1,2])\n",
    "    predicted_masks=tf.gather_nd(pm, classlabels)\n",
    "    predicted_masks=tf.expand_dims(predicted_masks, axis=-1)\n",
    "\n",
    "    \n",
    "    gm=tf.cast(tf.gather_nd(gt_mask,indices),tf.float32)\n",
    "    gt_masks=tf.cast(tf.gather_nd(gm,foregroundindices),tf.float32)\n",
    "\n",
    "    lf=tf.keras.losses.binary_crossentropy(gt_masks,predicted_masks)\n",
    "    loss=tf.reduce_sum(lf)\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_trainstep(maskheadmodel,rpnmodel,fmmodel):\n",
    "    #@tf.function(experimental_relax_shapes=True)\n",
    "    def mask_trainstep(images,labels, gt_box, masks, batchlen, mask_optimizer):\n",
    "        with tf.GradientTape() as gradientT:\n",
    "            featuremaps=fmmodel(images)\n",
    "            rpn_logits,rpn_probs,rpn_boxes=rpnmodel(featuremaps)\n",
    "            proposals=utils.get_proposals(rpn_probs,rpn_boxes,ALLANCHORS)            \n",
    "            indices,gt_deltas,gt_labels=utils.head_indices_deltas_labels(gt_box, labels, proposals, batchlen=batchlen, train_set_size=6)\n",
    "            fm_rois,mask_rois=utils.mask_roi_align(featuremaps,masks,proposals,MASKROISIZE)\n",
    "            predicted_masks=maskheadmodel(fm_rois)\n",
    "            maskloss=mask_loss(predicted_masks,mask_rois,gt_labels,indices)\n",
    "        gradients_of_maskhead = gradientT.gradient(maskloss, maskheadmodel.trainable_variables)\n",
    "        mask_optimizer.apply_gradients(zip(gradients_of_maskhead, maskheadmodel.trainable_variables))\n",
    "        return maskloss\n",
    "    return mask_trainstep\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_maskhead(maskheadmodel,rpnmodel, fmmodel,numofdatas,datafolder,maskfolder,jsonfile,batchlen, epochs,mask_optimizer=None):\n",
    "    if mask_optimizer is None:\n",
    "        mask_optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,clipvalue=0.5,clipnorm=1)\n",
    "        #mask_optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001,momentum=0.9,clipnorm=5.0)\n",
    "    trainstep=create_mask_trainstep(maskheadmodel,rpnmodel,fmmodel)\n",
    "    for epoch in range(epochs):\n",
    "        losses_m=[]\n",
    "        start = time.time()\n",
    "        batchgen=batchgenerator_maskrcnn(datafolder,maskfolder,jsonfile,batchlen,numofdatas,mode='Masktrain',fromimage=0)\n",
    "        for num,image_batch in enumerate(batchgen):\n",
    "            x,y,bb,m,fnames=image_batch\n",
    "            maskloss=trainstep(x,y,bb,m,batchlen,mask_optimizer)\n",
    "            losses_m.append(maskloss)\n",
    "        end = time.time()\n",
    "        print(round(end-start),'sec. \\t',epoch,'.epoch: \\t loss:\\t',np.mean(losses_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_maskhead(maskheadmodel=MASKHEAD,rpnmodel=rpnmodel,fmmodel=fmmodel,numofdatas=NUMOFTRAINDATAS,datafolder=IMAGEFOLDER,maskfolder=MASKFOLDER,jsonfile=DATAJSON,batchlen=5,epochs=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASKHEAD.save('saved_models/maskhead_10epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskheadmodel=tf.keras.models.load_model('saved_models/maskhead_10epochs.h5',compile='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch,masks_batch,bbox_batch,label_batch=utils.read_batch(IMAGEFOLDER,MASKFOLDER,DATAJSON,batchlen=BATCHLEN,start=0)\n",
    "predicted_mask_batch,predicted_boxes_batch,predicted_scores_batch,predicted_label_batch=model_utils.predict_all(image_batch,ALLANCHORS,BATCHLEN,fmmodel,rpnmodel,classheadmodel,maskheadmodel)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "utils.visualize_results(image_batch,predicted_mask_batch,predicted_label_batch,predicted_boxes_batch,predicted_scores_batch,CLASSDICT,BATCHLEN,masks_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_complex_trainstep(fmmodel,rpnmodel,classheadmodel,maskheadmodel):\n",
    "    #@tf.function(experimental_relax_shapes=True)\n",
    "    def complex_trainstep(images,gt_labels, gt_box,gt_masks,allanchors, batchlen,proposalcount,roisize,maskroisize, complex_optimizer):\n",
    "        with tf.GradientTape() as gradientT:\n",
    "            \n",
    "            featuremaps=fmmodel(images)\n",
    "            \n",
    "            #RPN\n",
    "            rpn_logits,rpn_probs,rpn_deltas = rpnmodel(featuremaps)    #Itt kapjuk meg az RPN kimeneteket\n",
    "            rpn_indices,rpn_gt_deltas,rpn_gt_labels=utils.indices_deltas_labels(gt_box,allanchors,batchlen,proposalcount,mode='pixelwise')\n",
    "            rpn_loss_class,rpn_loss_delta = rpn_loss(rpn_logits, rpn_deltas, rpn_gt_labels, rpn_gt_deltas, rpn_indices, batchlen)                \n",
    "            rpn_loss_w=rpn_loss_class+rpn_loss_delta\n",
    "            \n",
    "            #CH-BoxRefinement\n",
    "            proposals=utils.get_proposals(rpn_probs,rpn_deltas,allanchors)            \n",
    "            ch_indices,ch_gt_deltas,ch_gt_labels=utils.head_indices_deltas_labels(gt_box, gt_labels, proposals, batchlen=batchlen, train_set_size=6)\n",
    "            aligned_rois=utils.roi_align(featuremaps,proposals,roisize)\n",
    "            ch_logits,ch_probs,ch_deltas= classheadmodel(aligned_rois)  \n",
    "            ch_classloss,ch_deltaloss = ch_loss(ch_logits, ch_deltas, ch_gt_labels, ch_gt_deltas, ch_indices)   \n",
    "            ch_loss_w=ch_classloss+ch_deltaloss\n",
    "            \n",
    "            #Maskhead\n",
    "            fm_rois,mask_rois=utils.mask_roi_align(featuremaps,gt_masks,proposals,maskroisize)\n",
    "            predicted_masks=maskheadmodel(fm_rois)\n",
    "            maskloss=mask_loss(predicted_masks,mask_rois,ch_gt_labels,ch_indices)\n",
    "            \n",
    "            \n",
    "            #Complex loss and variables\n",
    "            complexloss=rpn_loss_w+ch_loss_w+maskloss\n",
    "            complextrainables=fmmodel.trainable_variables+rpnmodel.trainable_variables+classheadmodel.trainable_variables+maskheadmodel.trainable_variables\n",
    "        \n",
    "        gradients = gradientT.gradient(complexloss, complextrainables)\n",
    "        complex_optimizer.apply_gradients(zip(gradients, complextrainables))\n",
    "        return rpn_loss_w,ch_loss_w,maskloss\n",
    "    return complex_trainstep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_complex(fmmodel,rpnmodel,classheadmodel,maskheadmodel,allanchors,proposalcount,roisize,maskroisize,numofdatas,datafolder,maskfolder,jsonfile,batchlen, epochs,trainfromimage=0,complex_optimizer=None):\n",
    "    if complex_optimizer is None:\n",
    "        complex_optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,clipvalue=0.5,clipnorm=1)\n",
    "        #mask_optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001,momentum=0.9,clipnorm=5.0)\n",
    "    trainstep=create_complex_trainstep(fmmodel,rpnmodel,classheadmodel,maskheadmodel)\n",
    "    for epoch in range(epochs):\n",
    "        rpnlosses=[]\n",
    "        chlosses=[]\n",
    "        masklosses=[]\n",
    "        \n",
    "        start = time.time()\n",
    "        batchgen=batchgenerator_maskrcnn(datafolder,maskfolder,jsonfile,batchlen,numofdatas,mode='Complextrain',fromimage=trainfromimage)\n",
    "        for num,image_batch in enumerate(batchgen):\n",
    "            x,y,bb,m,fnames=image_batch\n",
    "            rpnloss,chloss,maskloss=trainstep(x,y,bb,m,allanchors,batchlen,proposalcount,roisize,maskroisize,complex_optimizer)\n",
    "            \n",
    "            rpnlosses.append(rpnloss)\n",
    "            chlosses.append(chloss)\n",
    "            masklosses.append(maskloss)\n",
    "\n",
    "        end = time.time()\n",
    "        print(round(end-start),'sec. \\t',epoch,'.epoch: \\t rpn loss:',np.mean(rpnlosses),'\\tch loss:',np.mean(chlosses),'\\tmask loss:',np.mean(masklosses))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_complex(fmmodel=fmmodel,rpnmodel=rpnmodel,classheadmodel=classheadmodel,maskheadmodel=maskheadmodel,\\\n",
    "                          allanchors=ALLANCHORS,proposalcount=PROPOSALCOUNT, roisize=ROISIZE,maskroisize=MASKROISIZE,\\\n",
    "                          numofdatas=NUMOFTRAINDATAS,datafolder=IMAGEFOLDER,maskfolder=MASKFOLDER,jsonfile=DATAJSON,batchlen=BATCHLEN,epochs=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch,masks_batch,bbox_batch,label_batch=utils.read_batch(IMAGEFOLDER,MASKFOLDER,DATAJSON,batchlen=BATCHLEN,start=4444)\n",
    "predicted_mask_batch,predicted_boxes_batch,predicted_scores_batch,predicted_label_batch=model_utils.predict_all(image_batch,ALLANCHORS,BATCHLEN,fmmodel,rpnmodel,classheadmodel,maskheadmodel)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "utils.visualize_results(image_batch,predicted_mask_batch,predicted_label_batch,predicted_boxes_batch,predicted_scores_batch,CLASSDICT,BATCHLEN,masks_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5d1fad6ca72abdf8fcb52ca6feb88ed3a0fe2233e35960763f5e765e082b37c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
